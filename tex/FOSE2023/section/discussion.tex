\section{考察と拡大質問\label{consideration}}
  \begin{figure}[t]
    \begin{verbatim}
      =======
      Suggestion 1

      def alloy(a,b):
          if a == 0:
              return 'Silver'
          elif b == 0:
              return 'Gold'
          else:
              return 'Alloy'

      =======
      Suggestion 2

      def problem212_a():
          a, b = map(int, input().split())
          if a > 0 and b == 0:
              print("Gold")
          elif a == 0 and b >

      =======
      Suggestion 3

      def main():
          a,b = map(int, input().split())
          if a > 0 and b == 0:
              print("Gold")
          elif a == 0 and b > 0:
    \end{verbatim}
    \label{recommend_212_A_en}
    \caption{問題212-Aの英語版に対する推薦スクリプトの一例}
  \end{figure}
  \ref{result}章で示した結果について，考察および拡大質問を示す．
  表\ref{En_accuracy}, \ref{Ja_accuracy}, \ref{Zh_accuracy}のうち，
  各言語の$Accuracy$の差が3.0\%以上だった問題の最大値に着目すると，推薦された全スクリプト数が5回のうち最も少なく，
  このことから，推薦スクリプトを最大10個取得することで，かえって$Accuracy$が低下する可能性が示唆され，
  Copilotの推薦順序も考慮すべきかという問題が明らかとなった．

  また，難易度別に推薦された全スクリプト数に着目すると，A問題はB, C, D問題に比べて，推薦された全スクリプト数が最も少なかった．
  これは問題が単純であるが故に，Copilotがスクリプトを推薦する際に，生成されるスクリプトの多様性が低くなるためであると考えられる．

  さらに，言語別で推薦された全スクリプト数の平均と，日本語のデータセットの$Accuracy$が最も高かったことより，
  日本語での入力により，Copilotがより最適なスクリプトのみを推薦していることがわかる．
  この理由として，AtCoder\cite{AtCoder}が日本で運営されているため，
  より多くの日本人がAtCoderを使用しており，日本語のコメントを含んだ回答がGitHub上にアップロードされ，それらが学習時に多く使用されたためであると考えられる．
  また，英語や中国語は日本語より多く使用されているため，
  より多くのスクリプトから学習を行ったことで，かえって$Accuracy$が低下した可能性がある．    

  表\ref{Med_accuracy}より，中国語のデータセットは，英語のデータセットに比べて，日本語のデータセットとの$Accuracy$の差が大きかった．
  これは，AtCoder\cite{AtCoder}において，日本語と英語の問題が準備されているため，
  日本語や英語のコメントを含んだより多くの正解プログラムが学習時に使用されたためであると考えられる．
  さらに中国語の生成スクリプトが最も多かった原因としては，
  AtCoderの中国語版が存在しないため，GitHub上に中国語のコメントを含んだ正解プログラムが少なく，
  推薦プログラムが絞りきれず，多くのスクリプトが推薦された可能性があり，
  これに対して，データセットを変更した調査が必要である．
  
  また，A問題に関しては特に大きな差が生じ，日本語との差が16.0\%，英語との差が11.5\%であった．
  A問題は今回使用したデータセットの難易度の中で最も簡単な問題であるため，
  $Accuracy$の値に大きな差が生じにくいと予測していたが，予測とは異なる結果となった．
  その理由として，AtCoder\cite{AtCoder}において，日本語と英語の問題が準備されているため，
  簡単な問題であっても，これらの言語をコメントに含んだより多くの正解プログラムがGitHub上にアプロードされており，
  それらが学習に使用された可能性がある．
  
  その他の原因探索のため，実際に$Accuracy$の差が大きかった問題をいくつか確認した．
  図\ref{problem_212_A_en}の問題は，
  英語および日本語のデータセットでは，全ての推薦スクリプトが全てのテストケースを通過しているが，
  中国語のデータセットでは，全ての推薦スクリプトが全てのテストケースを通過していない例である．
  また，図\ref{recommend_212_A_en}は実際に問題212-Aにおける中国語のデータセットに対する推薦スクリプトである．
  図\ref{recommend_212_A_en}より，単純な条件のみで構成されているものや，
  条件分岐の途中で推薦が打ち切られているもの，条件分岐の数が少ないものであった．
  
  この問題のように，条件が複数ある場合や，条件が複雑である場合，出力が文字列である場合に
  特に英語および日本語との$Accuracy$の差が大きくなる傾向があった．
  この原因として，AtCoderの文字列の出力形式がローマ字や英単語であるため，
  入力として使用した中国語のデータセットの文章中にローマ字や英単語が含まれており，
  それらがシンボルとして認識されなかった可能性や翻訳してデータセットを作成した影響が考えられる．

  結果として，言語を変更することで大規模言語モデルの学習対象となるデータが変化し，
  その影響により，推薦スクリプトの精度が変化するという問題が明らかとなった．
  大規模言語モデルはブラックボックスであり，今回明らかになった問題解決に取り組むとともに，
  今後も更なる調査を行うことが必要である．