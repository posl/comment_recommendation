\section{考察\label{discussion}}
  \begin{figure}[t]
    \begin{verbatim}
      =======
      Suggestion 1

      def alloy(a,b):
          if a == 0:
              return 'Silver'
          elif b == 0:
              return 'Gold'
          else:
              return 'Alloy'

      =======
      Suggestion 2

      def problem212_a():
          a, b = map(int, input().split())
          if a > 0 and b == 0:
              print("Gold")
          elif a == 0 and b >

      =======
      Suggestion 3

      def main():
          a,b = map(int, input().split())
          if a > 0 and b == 0:
              print("Gold")
          elif a == 0 and b > 0:
    \end{verbatim}
    \caption{問題212-Aの中国版に対する推薦コードの一例}
    \label{recommend_212_A_en}
  \end{figure}
  \ref{result}章で示した結果について，現時点での筆者の考察を述べる．
  これらは筆者の考察であるため，今後の実験により検証されなければならない．
  \vspace{-1zh}
  %\subsection{考察\label{consideration}}
  %\subsubsection{推薦コードの生成数と正答率の関係}
  \subsection{推薦コードの生成数と正答率の関係}
  表\ref{En_accuracy}, \ref{Ja_accuracy}, \ref{Zh_accuracy}のうち，
  各言語の$Accuracy$の差が3.0\%以上だった問題の最大値に着目すると，推薦された全コード数が5回のうち最も少なく，
  このことから，推薦1回につき推薦コードを最大10個取得することで，かえって$Accuracy$が低下した可能性が考えられる．

  また，難易度別に推薦された全コード数に着目すると，A問題はB, C, D問題に比べて，推薦された全コード数が最も少なかった．
  これはA問題が基本的な文法を問う問題であるため，処理が単純であり，
  類似した文面のコードが推薦されると重複として除外されている可能性があると考えた．
  %これは問題が単純であるが故に，Copilotがコードを推薦する際に，生成されるコードの多様性が低くなるためであると考えられる．

  さらに，言語別で推薦された全コード数の平均と，日本語のデータセットの$Accuracy$が最も高かったことより，
  日本語での入力により，Copilotがより最適なコードのみを推薦していることがわかる．
  この理由として，AtCoder\cite{AtCoder}が日本で運営されているため，
  多くの日本人がAtCoderを使用しており，日本語のコメントを含んだ回答がよりアップロードされ，それらが学習時に多く使用されたためであると考えられる．
  %また，英語や中国語は日本語より多く使用されているため，
  %より多くのスクリプトから学習を行ったことで，かえって$Accuracy$が低下した可能性がある．    
  %\subsubsection{中国語データセットにおける正答率の低下}
  \subsection{中国語データセットにおける正答率の低下}
  表\ref{Med_accuracy}より，中国語のデータセットは，英語のデータセットに比べて，日本語のデータセットとの$Accuracy$の差が大きかった．
  これは，AtCoder\cite{AtCoder}において，日本語と英語の問題が準備されているため，
  日本語や英語のコメントを含んだより多くの正解コードが学習時に使用されたためであると考えられる．
  さらに中国語の生成コードが最も多かった原因としては，
  AtCoderの中国語版が存在しないため，中国語のコメントを含んだ正解コードの数が少なかった可能性がある．
  これに対して中国語を基とするプログラミングコンテストのデータセットを使用して調査を行う必要がある．
  %推薦プログラムが絞りきれず，多くのスクリプトが推薦された可能性があり，これに対して，データセットを変更した調査が必要である．
  
  また，A問題に関しては特に大きな差が生じ，日本語との差が16.0\%，英語との差が11.5\%であった．
  A問題は今回使用したデータセットの難易度の中で最も簡単な問題であるため，
  $Accuracy$の値に大きな差が生じにくいと予測していたが，予測とは異なる結果となった．
  その理由として，AtCoder\cite{AtCoder}において，日本語と英語の問題が準備されているため，
  簡単な問題であっても，これらの言語をコメントに含んだより多くの正解コードがアップロードされており，
  それらが学習に使用された可能性がある．

  その他の原因探索のため，実際に$Accuracy$の差が大きかった問題をいくつか確認した．
  図\ref{problem_212_A_en}の問題は，
  英語および日本語のデータセットでは，全ての推薦コードが全てのテストケースを通過しているが，
  中国語のデータセットでは，全ての推薦コードが全てのテストケースを通過していない例である．
  また，図\ref{recommend_212_A_en}は実際に問題212-Aにおける中国語のデータセットに対する推薦コードである．
  図\ref{recommend_212_A_en}より，単純な条件のみで構成されているものや，
  条件分岐の途中で推薦が打ち切られているもの，条件分岐の数が少ないものであった．
  
  この問題のように，条件が複数ある場合や，条件が複雑である場合，出力が文字列である場合に
  特に英語および日本語との$Accuracy$の差が大きくなる傾向があった．
  この原因として，AtCoderの文字列の出力形式がローマ字や英単語であるため，
  入力として使用した中国語のデータセットの文章中にローマ字や英単語が含まれており，
  それらがシンボルとして認識されなかった可能性や翻訳してデータセットを作成した影響が考えられる．


 % \subsection{未解決課題\label{open_issues}}
 % %\subsubsection{タスクによって最適な言語が異なる可能性}
 %   表\ref{En_accuracy}, \ref{Ja_accuracy}, \ref{Zh_accuracy}より，
 %   入力言語によって推薦コードの正当性および数に差が生じ，日本語，英語，中国語の順に$Accuracy$が高かった．
 %   このことから，入力言語が異なることで，大規模言語モデルの学習データに影響が生じ，
 %   推薦結果が変化する問題が明らかとなった．
 %   Ethnologueの調査結果\cite{Ethnologue}より，
 %   英語は約15億人，中国語は約11億人，日本語は約1.3億人が母国語あるいは第二言語として話しているため，
 %   英語，中国語，日本語の順に学習データは多いはずであるが，実際には日本語のデータセットの$Accuracy$が最も高かった．
 %   その理由として，大規模言語モデルはブラックボックスであり，どのような学習データが使用されているのかが明らかになっていないことが挙げられる．
 %   しかしながら，どのような学習データが使用されているか明らかにすることは現時点で困難である．
 %   そこで今回の調査において示唆された，ある特定のタスクにおいては英語以外の言語を使用した方が正答率が高い可能性について
 %   データセットを変更して調査を進める必要がある．
  
  
  
  %  \subsubsection{入力言語の違いによる学習データの変化}
  %  表\ref{En_accuracy}, \ref{Ja_accuracy}, \ref{Zh_accuracy}より，
  %  入力言語によって推薦コードの正当性および数に差が生じ，日本語，英語，中国語の順に$Accuracy$が高かった．
  %  このことから，入力言語が異なることで，大規模言語モデルの学習データに影響が生じ，
  %  推薦結果が変化する問題が明らかとなった．
  %  そのため，%今後は入力言語を使い分けることで，
  %  今後入力言語の違いによる学習データの変化を調査することで，
  %  学習データの影響を利用する方法を探索し，問題を解決する必要がある．

    %\ref{result}節より，入力言語によって$Accuracy$に差が生じ，日本語，英語，中国語の順に$Accuracy$が高かった．
    %また，表\ref{En_accuracy}, \ref{Ja_accuracy}, \ref{Zh_accuracy}より推薦スクリプト数も変化していることから，
    %入力言語を変化させることによって，大規模言語モデルの学習データに影響が生じ，精度が変化する問題が明らかとなった．

 % \subsubsection{大規模言語モデルのブラックボックス性}
 %   Ethnologueの調査結果\cite{Ethnologue}より，
 %   英語は約15億人，中国語は約11億人，日本語は約1.3億人が母国語あるいは第二言語として話しているため，
 %   英語，中国語，日本語の順に学習データは多いはずであるが，実際には日本語のデータセットの$Accuracy$が最も高かった．
 %   その理由として，大規模言語モデルはブラックボックスであり，どのような学習データが使用されているのかが明らかになっていないことが挙げられる．
 %   今回の調査において，ある特定のタスクにおいては英語以外の言語を使用した方が正答率が高い可能性が示唆されたため，
 %   データセットを変更して調査を進める必要がある．
    %そのため，今後GitHub上のデータを集計し，学習データを明らかにすることで，
    %大規模言語モデルのブラックボックス性を解消していく必要がある．
    