\section{考察と未解決課題\label{discussion}}
  \begin{figure}[t]
    \begin{verbatim}
      =======
      Suggestion 1

      def alloy(a,b):
          if a == 0:
              return 'Silver'
          elif b == 0:
              return 'Gold'
          else:
              return 'Alloy'

      =======
      Suggestion 2

      def problem212_a():
          a, b = map(int, input().split())
          if a > 0 and b == 0:
              print("Gold")
          elif a == 0 and b >

      =======
      Suggestion 3

      def main():
          a,b = map(int, input().split())
          if a > 0 and b == 0:
              print("Gold")
          elif a == 0 and b > 0:
    \end{verbatim}
    \caption{問題212-Aの英語版に対する推薦スクリプトの一例}
    \label{recommend_212_A_en}
  \end{figure}
  \ref{result}章で示した結果について，考察を行うとともに，未解決課題として何が残っているかを明らかにする．
  \vspace{-1zh}
  \subsection{考察\label{consideration}}
  \subsubsection{推薦スクリプトの生成数と正答率の関係}
  表\ref{En_accuracy}, \ref{Ja_accuracy}, \ref{Zh_accuracy}のうち，
  各言語の$Accuracy$の差が3.0\%以上だった問題の最大値に着目すると，推薦された全スクリプト数が5回のうち最も少なく，
  このことから，推薦スクリプトを最大10個取得することで，かえって$Accuracy$が低下した可能性が考えられる．

  また，難易度別に推薦された全スクリプト数に着目すると，A問題はB, C, D問題に比べて，推薦された全スクリプト数が最も少なかった．
  これは問題が単純であるが故に，Copilotがスクリプトを推薦する際に，生成されるスクリプトの多様性が低くなるためであると考えられる．

  さらに，言語別で推薦された全スクリプト数の平均と，日本語のデータセットの$Accuracy$が最も高かったことより，
  日本語での入力により，Copilotがより最適なスクリプトのみを推薦していることがわかる．
  この理由として，AtCoder\cite{AtCoder}が日本で運営されているため，
  より多くの日本人がAtCoderを使用しており，日本語のコメントを含んだ回答がGitHub上にアップロードされ，それらが学習時に多く使用されたためであると考えられる．
  また，英語や中国語は日本語より多く使用されているため，
  より多くのスクリプトから学習を行ったことで，かえって$Accuracy$が低下した可能性がある．    
  \subsubsection{中国語データセットにおける正答率の低下}
  表\ref{Med_accuracy}より，中国語のデータセットは，英語のデータセットに比べて，日本語のデータセットとの$Accuracy$の差が大きかった．
  これは，AtCoder\cite{AtCoder}において，日本語と英語の問題が準備されているため，
  日本語や英語のコメントを含んだより多くの正解プログラムが学習時に使用されたためであると考えられる．
  さらに中国語の生成スクリプトが最も多かった原因としては，
  AtCoderの中国語版が存在しないため，GitHub上に中国語のコメントを含んだ正解プログラムが少なく，
  推薦プログラムが絞りきれず，多くのスクリプトが推薦された可能性があり，これに対して，データセットを変更した調査が必要である．
  
  また，A問題に関しては特に大きな差が生じ，日本語との差が16.0\%，英語との差が11.5\%であった．
  A問題は今回使用したデータセットの難易度の中で最も簡単な問題であるため，
  $Accuracy$の値に大きな差が生じにくいと予測していたが，予測とは異なる結果となった．
  その理由として，AtCoder\cite{AtCoder}において，日本語と英語の問題が準備されているため，
  簡単な問題であっても，これらの言語をコメントに含んだより多くの正解プログラムがGitHub上にアップロードされており，
  それらが学習に使用された可能性がある．

  その他の原因探索のため，実際に$Accuracy$の差が大きかった問題をいくつか確認した．
  図\ref{problem_212_A_en}の問題は，
  英語および日本語のデータセットでは，全ての推薦スクリプトが全てのテストケースを通過しているが，
  中国語のデータセットでは，全ての推薦スクリプトが全てのテストケースを通過していない例である．
  また，図\ref{recommend_212_A_en}は実際に問題212-Aにおける中国語のデータセットに対する推薦スクリプトである．
  図\ref{recommend_212_A_en}より，単純な条件のみで構成されているものや，
  条件分岐の途中で推薦が打ち切られているもの，条件分岐の数が少ないものであった．
  
  この問題のように，条件が複数ある場合や，条件が複雑である場合，出力が文字列である場合に
  特に英語および日本語との$Accuracy$の差が大きくなる傾向があった．
  この原因として，AtCoderの文字列の出力形式がローマ字や英単語であるため，
  入力として使用した中国語のデータセットの文章中にローマ字や英単語が含まれており，
  それらがシンボルとして認識されなかった可能性や翻訳してデータセットを作成した影響が考えられる．


  \subsection{未解決課題\label{open_issues}}
  \subsubsection{入力言語の違いによる学習データの変化}
    表\ref{En_accuracy}, \ref{Ja_accuracy}, \ref{Zh_accuracy}より，
    入力言語によって推薦スクリプトの正当性および数に差が生じ，日本語，英語，中国語の順に$Accuracy$が高かった．
    このことから，入力言語が異なることで，大規模言語モデルの学習データに影響が生じ，
    推薦結果が変化する問題が明らかとなった．
    そのため，%今後は入力言語を使い分けることで，
    今後入力言語の違いによる学習データの変化を調査することで，
    学習データの影響を利用する方法を探索し，問題を解決する必要がある．

    %\ref{result}節より，入力言語によって$Accuracy$に差が生じ，日本語，英語，中国語の順に$Accuracy$が高かった．
    %また，表\ref{En_accuracy}, \ref{Ja_accuracy}, \ref{Zh_accuracy}より推薦スクリプト数も変化していることから，
    %入力言語を変化させることによって，大規模言語モデルの学習データに影響が生じ，精度が変化する問題が明らかとなった．

  \subsubsection{大規模言語モデルのブラックボックス性}
    Ethnologueの調査結果\cite{Ethnologue}より，
    英語は約15億人，中国語は約11億人，日本語は約1.3億人が母国語あるいは第二言語として話しているため，
    英語，中国語，日本語の順に学習データは多いはずであるが，実際には日本語のデータセットの$Accuracy$が最も高かった．
    その理由として，大規模言語モデルはブラックボックスであり，どのような学習データが使用されているのかが明らかになっていないことが挙げられる．
    そのため，今後GitHub上のデータを集計し，学習データを明らかにすることで，
    大規模言語モデルのブラックボックス性を解消していく必要がある．
    